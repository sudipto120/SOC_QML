{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99769ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SPSA:\n",
    "    def __init__(self, maxiter=100, a=0.1, c=0.05, A=0, alpha=0.602, gamma=0.101):\n",
    "        \n",
    "        self.maxiter = maxiter\n",
    "        self.a = a\n",
    "        self.c = c\n",
    "        self.A = A\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def minimize(self, objective_function, initial_params):\n",
    "    \n",
    "        params = np.array(initial_params, dtype=float)\n",
    "        num_params = len(params)\n",
    "        cost_history = []\n",
    "\n",
    "        print(\"Starting SPSA optimization...\")\n",
    "        \n",
    "        for k in range(self.maxiter):\n",
    "            # Calculate iteration-dependent coefficients\n",
    "            ak = self.a / (k + 1 + self.A)**self.alpha\n",
    "            ck = self.c / (k + 1)**self.gamma\n",
    "\n",
    "            # Generate a random perturbation vector (Delta)\n",
    "            # Each element is randomly +1 or -1\n",
    "            delta = np.random.choice([-1, 1], size=num_params)\n",
    "\n",
    "            params_plus = params + ck * delta\n",
    "            params_minus = params - ck * delta\n",
    "\n",
    "\n",
    "            cost_plus = objective_function(params_plus)\n",
    "            cost_minus = objective_function(params_minus)\n",
    "            \n",
    "            current_cost = objective_function(params)\n",
    "            cost_history.append(current_cost)\n",
    "            \n",
    "            if (k + 1) % 10 == 0:\n",
    "                print(f\"Iter {k+1}/{self.maxiter} | Cost: {current_cost:.6f}\")\n",
    "\n",
    "\n",
    "            gradient_approx = (cost_plus - cost_minus) / (2 * ck * delta)\n",
    "\n",
    "            params = params - ak * gradient_approx\n",
    "        \n",
    "        print(\"Optimization finished.\")\n",
    "\n",
    "        return {\n",
    "            'optimal_params': params,\n",
    "            'final_cost': objective_function(params),\n",
    "            'cost_history': cost_history\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea792a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    def objective_function(params):\n",
    "        x, y = params\n",
    "        return x**2 + y**2\n",
    "\n",
    "    # Set the initial guess for the parameters\n",
    "    initial_params = np.array([3.0, -4.0])\n",
    "\n",
    "    # Instantiate the optimizer with hyperparameters\n",
    "    # Setting A = 10% of maxiter is a common practice\n",
    "    spsa_optimizer = SPSA(maxiter=200, A=20)\n",
    "\n",
    "    result = spsa_optimizer.minimize(objective_function, initial_params)\n",
    "\n",
    "    print(\"\\n--- Optimization Results ---\")\n",
    "    print(f\"Optimal Parameters: {result['optimal_params']}\")\n",
    "    print(f\"Final Cost: {result['final_cost']:.6f}\")\n",
    "\n",
    "    # Plot the convergence\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(result['cost_history'], 'b-')\n",
    "    plt.title(\"SPSA Optimization Convergence\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
